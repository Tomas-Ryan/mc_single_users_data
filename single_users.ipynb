{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PIL\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image as XLImage \n",
    "from PIL import Image as PILImage\n",
    "import shutil\n",
    "import os\n",
    "import zipfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imput request date YYY-MM-DD\n",
    "request_date = '2024-11-08'\n",
    "\n",
    "# Imput email column\n",
    "input_file_email_column = 'Email'\n",
    "\n",
    "# imput file path definition\n",
    "input_file_path = request_date + '/' + request_date + '_request.xlsx'\n",
    "\n",
    "# Users data file path definition\n",
    "data_path = request_date + '/' + request_date + '_users_data.xlsx'\n",
    "\n",
    "# Output directory definition\n",
    "output_folder = request_date + '/' + request_date + '_output'\n",
    "\n",
    "# Base files\n",
    "logo_path = \"mc_logo.png\"\n",
    "template_path = \"irm template.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directory if needed\n",
    "os.makedirs(request_date, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that generates a query\n",
    "\n",
    "def generate_query(input_file_path, email_column='Email'):\n",
    "    # Base query\n",
    "    base_query = \"\"\"--query used for the requests of user single data\n",
    "SELECT\n",
    "profileid AS`ProfileId`,\n",
    "first_name AS`First Name`,\n",
    "last_name AS`Last Name`,\n",
    "normalized_name AS`Normalized Name`,\n",
    "date(FROM_UNIXTIME(birth_date / 1000)) AS`Birthdate`,\n",
    "email AS`Primary Email Address`,\n",
    "email_addresses_all AS`Email Addresses (all)`,\n",
    "REPLACE(primary_phone, '+', '') AS`Primary Phone`,\n",
    "REPLACE(phone_number, '+', '') AS`Phone Numbers`,\n",
    "REPLACE(phone_numbers_all, '+', '') AS`Phone Numbers (all)`,\n",
    "REPLACE(shopify_phone, '+', '') AS`Shopify Phone`,\n",
    "email_campaign_id_all AS`Email CampaignId (all)`,\n",
    "email_id_all AS`EmailId (all)`,\n",
    "city AS`City (all)`,\n",
    "mr_geo_city_name AS`City (mostrecent)`,\n",
    "geo_city_name AS`Cityname`,\n",
    "geo_subdivision_1_name AS`State (all)`,\n",
    "mr_geo_subdivision_1_name AS`State (mostrecent)`,\n",
    "geo_subdivision_1_iso_code AS`Statecode (all)`,\n",
    "mr_geo_subdivision_1_iso_code AS`Statecode (mostrecent)`,\n",
    "geo_subdivision_2_name AS`County (all)`,\n",
    "mr_geo_subdivision_2_name AS`County (mostrecent)`,\n",
    "geo_subdivision_2_iso_code AS`Countycode (all)`,\n",
    "mr_geo_subdivision_2_iso_code AS`Countycode (mostrecent)`,\n",
    "geo_continent_code AS`Continentcode (all)`,\n",
    "geo_continent_name AS`Continent (all)`,\n",
    "geo_country_iso_code AS`Countrycode`,\n",
    "country AS`Country (all)`,\n",
    "geo_metro_code AS`DesignatedMarketAreacode (all)`,\n",
    "mr_geo_metro_code AS`Designated Market Area code (mostrecent)`,\n",
    "geo_geoname_id AS`GeonameID (all)`, \n",
    "mr_geo_geoname_id AS`GeonameID (mostrecent)`,\n",
    "geo_latlong AS`Coordinates (all)`, \n",
    "geo_time_zone AS`Timezone (all)`,\n",
    "mr_geo_time_zone AS`Timezone (mostrecent)`,\n",
    "geo_zipcode AS`Zipcode`,\n",
    "mr_geo_zipcode AS`Zipcode (mostrecent)`,\n",
    "postal_code AS`Postalcode`,\n",
    "language AS`Language`,\n",
    "experian_ethnic_religion AS`Experian Ethnic Religion`,\n",
    "experian_gender AS`Experian Gender`\n",
    "from prod_products.cdp_reporting.bcexport_allconsumers\n",
    "WHERE email in (\n",
    "{email_list}\n",
    ")\"\"\"\n",
    "\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(input_file_path)\n",
    "    \n",
    "    # Extract emails, convert to lowercase, and format them\n",
    "    emails = df[email_column].str.lower().tolist()\n",
    "    formatted_emails = ',\\n'.join(f'\"{email}\"' for email in emails)\n",
    "    \n",
    "    # Insert formatted emails into query\n",
    "    final_query = base_query.format(email_list=formatted_emails)\n",
    "    \n",
    "    return final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_emails(source1, source2, email_col1='Primary Email Address', email_col2='Primary Email Address'):\n",
    "    \"\"\"\n",
    "    Compares emails between two sources (Excel files or pandas DataFrames).\n",
    "    \n",
    "    Parameters:\n",
    "    - source1: first source (path to Excel file or pandas DataFrame)\n",
    "    - source2: second source (path to Excel file or pandas DataFrame)\n",
    "    - email_col1: email column name in source 1\n",
    "    - email_col2: email column name in source 2\n",
    "    \n",
    "    Returns:\n",
    "    - List of emails present in source1 but not in source2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle different input types for source1\n",
    "    if isinstance(source1, str):\n",
    "        df1 = pd.read_excel(source1)\n",
    "    elif isinstance(source1, pd.DataFrame):\n",
    "        df1 = source1.copy()\n",
    "    else:\n",
    "        raise ValueError(\"source1 must be either a file path (str) or a pandas DataFrame\")\n",
    "\n",
    "    # Handle different input types for source2\n",
    "    if isinstance(source2, str):\n",
    "        df2 = pd.read_excel(source2)\n",
    "    elif isinstance(source2, pd.DataFrame):\n",
    "        df2 = source2.copy()\n",
    "    else:\n",
    "        raise ValueError(\"source2 must be either a file path (str) or a pandas DataFrame\")\n",
    "    \n",
    "    # Convert emails to lowercase and remove whitespace\n",
    "    df1[email_col1] = df1[email_col1].str.lower().str.strip()\n",
    "    df2[email_col2] = df2[email_col2].str.lower().str.strip()\n",
    "    \n",
    "    # Create email sets\n",
    "    emails1 = set(df1[email_col1].dropna())\n",
    "    emails2 = set(df2[email_col2].dropna())\n",
    "    \n",
    "    # Find emails not present in source 2\n",
    "    missing_emails = list(emails1 - emails2)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nTotal emails in source 1: {len(emails1)}\")\n",
    "    print(f\"Total emails in source 2: {len(emails2)}\")\n",
    "    print(f\"Emails not found: {len(missing_emails)}\")\n",
    "    print(f\"Not found percentage: {(len(missing_emails)/len(emails1))*100:.2f}%\")\n",
    "    \n",
    "    return missing_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_generate_files(request_date, template_path, excel_path, json_folder, output_folder, logo_path, properties_mapping):\n",
    "    \"\"\"\n",
    "    Función combinada que procesa datos de Excel y JSON, y genera archivos individuales\n",
    "    \"\"\"\n",
    "    # 1. Cargar datos del Excel inicial\n",
    "    df_excel = pd.read_excel(excel_path)\n",
    "    \n",
    "    # 2. Procesar archivos JSON con todas las transformaciones\n",
    "    all_data = []\n",
    "    for filename in os.listdir(json_folder):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(json_folder, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            row_data = {\n",
    "                'Creation Date': data['creationDate'],\n",
    "                'ID': data['id']\n",
    "            }\n",
    "            \n",
    "            # Inicializar con None\n",
    "            for old_name, new_name in properties_mapping.items():\n",
    "                row_data[new_name] = None\n",
    "            \n",
    "            # Procesar propiedades con transformaciones\n",
    "            for prop in data['properties']['property']:\n",
    "                if prop['id'] in properties_mapping:\n",
    "                    value = prop['values'][0] if prop['values'] else None\n",
    "                    \n",
    "                    # Aplicar transformaciones específicas\n",
    "                    if value is not None:\n",
    "                        if prop['id'] in ['primary_phone', 'phone_number', 'phone_numbers_all', 'shopify_phone']:\n",
    "                            value = value.replace('+', '')\n",
    "                        elif prop['id'] == 'birth_date':\n",
    "                            try:\n",
    "                                timestamp = int(value) / 1000\n",
    "                                value = pd.to_datetime(timestamp, unit='s').strftime('%Y-%m-%d')\n",
    "                            except (ValueError, TypeError):\n",
    "                                value = None\n",
    "                    \n",
    "                    row_data[properties_mapping[prop['id']]] = value\n",
    "            \n",
    "            all_data.append(row_data)\n",
    "    \n",
    "    # Crear DataFrame de JSON\n",
    "    df_json = pd.DataFrame(all_data)\n",
    "    \n",
    "    # 3. Concatenar DataFrames (apilar filas)\n",
    "    df_combined = pd.concat([df_excel, df_json], ignore_index=True)\n",
    "    \n",
    "    # 4. Crear archivos individuales y ZIP\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    created_files = []\n",
    "    \n",
    "    # Iterar sobre el DataFrame combinado\n",
    "    for _, row in df_combined.iterrows():\n",
    "        email = row['Primary Email Address']\n",
    "        if pd.isna(email):\n",
    "            continue\n",
    "            \n",
    "        output_path = f\"{output_folder}/{email}.xlsx\"\n",
    "        shutil.copyfile(template_path, output_path)\n",
    "        \n",
    "        # Modificar archivo Excel\n",
    "        wb = load_workbook(output_path)\n",
    "        ws = wb.active\n",
    "        \n",
    "        # Insertar datos en fila 4\n",
    "        for col_idx, value in enumerate(row, start=1):\n",
    "            ws.cell(row=4, column=col_idx, value=value)\n",
    "        \n",
    "        # Añadir logo\n",
    "        img = XLImage(logo_path)\n",
    "        ws.add_image(img, \"A1\")\n",
    "        \n",
    "        wb.save(output_path)\n",
    "        print(f\"File saved: {output_path}\")\n",
    "        created_files.append(output_path)\n",
    "    \n",
    "    # Crear archivo ZIP\n",
    "    zip_path = f\"{output_folder}/{request_date}.zip\"\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for file in created_files:\n",
    "            zipf.write(file, os.path.basename(file))\n",
    "    \n",
    "    print(f\"ZIP file created: {zip_path}\")\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create databricks query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = generate_query(input_file_path, email_column=input_file_email_column)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function usage:\n",
    "missing_df = check_emails(\n",
    "    input_file_path,\n",
    "    data_path,\n",
    "    email_col1=input_file_email_column,  # Adjust according to column names\n",
    "    email_col2='Primary Email Address'\n",
    ")\n",
    "\n",
    "# View not found emails\n",
    "print(\"\\nNot found emails:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create users data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Primero definir el properties_mapping\n",
    "properties_mapping = {\n",
    "    'profileid': 'ProfileId',\n",
    "    'first_name': 'First Name',\n",
    "    'last_name': 'Last Name',\n",
    "    'normalized_name': 'Normalized Name',\n",
    "    'birth_date': 'Birthdate',\n",
    "    'email': 'Primary Email Address',\n",
    "    'email_addresses_all': 'Email Addresses (all)',\n",
    "    'primary_phone': 'Primary Phone',\n",
    "    'phone_number': 'Phone Numbers',\n",
    "    'phone_numbers_all': 'Phone Numbers (all)',\n",
    "    'shopify_phone': 'Shopify Phone',\n",
    "    'email_campaign_id_all': 'Email CampaignId (all)',\n",
    "    'email_id_all': 'EmailId (all)',\n",
    "    'city': 'City (all)',\n",
    "    'mr_geo_city_name': 'City (mostrecent)',\n",
    "    'geo_city_name': 'Cityname',\n",
    "    'geo_subdivision_1_name': 'State (all)',\n",
    "    'mr_geo_subdivision_1_name': 'State (mostrecent)',\n",
    "    'geo_subdivision_1_iso_code': 'Statecode (all)',\n",
    "    'mr_geo_subdivision_1_iso_code': 'Statecode (mostrecent)',\n",
    "    'geo_subdivision_2_name': 'County (all)',\n",
    "    'mr_geo_subdivision_2_name': 'County (mostrecent)',\n",
    "    'geo_subdivision_2_iso_code': 'Countycode (all)',\n",
    "    'mr_geo_subdivision_2_iso_code': 'Countycode (mostrecent)',\n",
    "    'geo_continent_code': 'Continentcode (all)',\n",
    "    'geo_continent_name': 'Continent (all)',\n",
    "    'geo_country_iso_code': 'Countrycode',\n",
    "    'country': 'Country (all)',\n",
    "    'geo_metro_code': 'DesignatedMarketAreacode (all)',\n",
    "    'mr_geo_metro_code': 'Designated Market Area code (mostrecent)',\n",
    "    'geo_geoname_id': 'GeonameID (all)',\n",
    "    'mr_geo_geoname_id': 'GeonameID (mostrecent)',\n",
    "    'geo_latlong': 'Coordinates (all)',\n",
    "    'geo_time_zone': 'Timezone (all)',\n",
    "    'mr_geo_time_zone': 'Timezone (mostrecent)',\n",
    "    'geo_zipcode': 'Zipcode',\n",
    "    'mr_geo_zipcode': 'Zipcode (mostrecent)',\n",
    "    'postal_code': 'Postalcode',\n",
    "    'language': 'Language',\n",
    "    'experian_ethnic_religion': 'Experian Ethnic Religion',\n",
    "    'experian_gender': 'Experian Gender'\n",
    "}\n",
    "\n",
    "# 2. Llamar a la función\n",
    "df_final = process_and_generate_files(\n",
    "    request_date=request_date,                          # Fecha para nombrar el ZIP\n",
    "    template_path='irm template.xlsx',         # Ruta de la plantilla Excel\n",
    "    excel_path=request_date + '/' + request_date + '_users_data.xlsx',            # Ruta del Excel inicial\n",
    "    json_folder= request_date,                 # Carpeta con archivos JSON\n",
    "    output_folder= request_date + '/' + request_date + '_output',        # Carpeta donde se guardarán los archivos\n",
    "    logo_path= 'mc_logo.png',                    # Ruta del logo\n",
    "    properties_mapping= properties_mapping               # Diccionario de mapeo definido arriba\n",
    ")\n",
    "\n",
    "# 3. Opcionalmente, revisar el DataFrame resultante\n",
    "print(df_final.shape)  # Ver dimensiones del DataFrame\n",
    "print(df_final.columns)  # Ver columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function usage:\n",
    "missing_df = check_emails(\n",
    "    input_file_path,\n",
    "    df_final,\n",
    "    email_col1=input_file_email_column,  # Adjust according to column names\n",
    "    email_col2='Primary Email Address'\n",
    ")\n",
    "\n",
    "# View not found emails\n",
    "print(\"\\nNot found emails:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1a950e37b41190e67bbbde20ca6c25157cc925a04f347a7d0b06334724b608a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
